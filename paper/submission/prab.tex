\documentclass[preprint,linenumbers,amsmath,amssymb,aps,prstab]{revtex4-1}%

\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{siunitx}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{fancyvrb}
%\usepackage{booktabs}
%\usepackage{amsmath}
%\usepackage{amsfonts}
\usepackage{url}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{listings}
\newcounter{lstmain}
\setcounter{lstmain}{1}
\usepackage{graphicx,xcolor,enumitem}
\usepackage{booktabs}


\lstnewenvironment{code}[1][]
{ \vspace{0.3cm}\footnotesize{\textsc{Code Listing \thelstmain: #1}}
  \hspace{0.1cm} \hrulefill
  \lstset{language=C++, basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue}\bfseries,commentstyle=\color{mygreen},
    stringstyle=\color{red}
  }
}
{
  \hrule \vspace{0.3cm}
  \addtocounter{lstmain}{1}
}

\lstnewenvironment{codeln}[1][]
{\textbf{Code Listing} \hspace{1cm} \hrulefill \lstset{language=C++, basicstyle=\ttfamily\scriptsize, numbers=left, numberstyle=\tiny, stepnumber=1, numbersep=5pt, keywordstyle=\color{blue}\bfseries,commentstyle=\color{mygreen}, stringstyle=\color{red}}}
{\hrule\smallskip}

\lstnewenvironment{smallcode}[1][]
{\lstset{language=C++, basicstyle=\ttfamily\scriptsize, keywordstyle=\color{myblue}\bfseries,commentstyle=\color{mygreen}, stringstyle=\color{red}}}
{\smallskip}

\xdefinecolor{mygreen}{RGB}{0,220,0}
\xdefinecolor{myblue}{RGB}{26,150,255}


\begin{document}

\title{A parallel general purpose multi-objective optimization framework,
	with application to electron beam dynamics}

\author{N. Neveu}
\altaffiliation[Also at ]{Argonne National Laboratory, USA}%Lines break automatically or can be forced with \\

\author{L. Spentzouris}
\affiliation{Illinois Institute of Technology, Chicago, IL}

\author{A. Adelmann}
\email{andreas.adelmann@psi.ch}
\author{Y. Ineichen }
%\email{yves.ineichen@gmail.com}
\author{A. Kolano}
\altaffiliation[Also at ]{
	University of Huddersfield, West Yorkshire, United Kingdom and  CERN, Genf}
\author{C. Metzger-Kraus}
\affiliation{
	PSI, Villigen, Switzerland}%

\author{C. Bekas}
\author{A. Curioni}

\affiliation{IBM Research, Zurich, Switzerland }%

\author{P. Arbenz}
\affiliation{%
	Department of Computer Science, ETH Zurich, Switzerland}%

\date{\today}% It is always \today, today,
%  but any date may be explicitly specified


\begin{abstract}
Particle accelerators are invaluable tools for research in the basic and applied sciences, such as materials science, chemistry,
  the biosciences, particle physics, nuclear physics and medicine. The design, commissioning, and operation of accelerator facilities is a
  non-trivial task, due to the large number of control parameters and the complex interplay of several conflicting design goals.
  The Argonne Wakefield Accelerator facility has some unique challenges resulting from its purpose to carry out advanced accelerator R\&D.
  Individual experiments often have challenging beam requirements, and the physical configuration of the beamlines is often changed
  to accommodate the variety of supported experiments. The need for rapid deployment of different operational settings
  further complicates the optimization work that must be done for multiple constraints and challenging operational regimes. 
  One example of this is an independently staged two-beam acceleration experiment which requires the construction 
  of an additional beamline (this is now in progress).  The high charge drive beam, well into the space charge regime, must be threaded
  through small aperture (17.6 mm) decelerating structures.  
  In addition, the bunch length must be sufficiently short to maximize power generation in the decelerator.  
We propose to tackle this problem by means of multi-objective optimization algorithms which also facilitate a parallel deployment.
In order to compute solutions in a meaningful time frame, a fast and scalable software framework is required.
In this paper, we present a general-purpose framework for simulation-based
multi-objective optimization methods that allows the automatic investigation of optimal sets of machine parameters.
Using evolutionary algorithms as the optimizer and \textsc{OPAL} as the forward solver, validation experiments and 
 results of multi-objective optimization problems in the domain of beam dynamics are presented. 
  Optimized solutions for the new high charge drive beamline found by the framework were used to finish the design 
  of a two beam acceleration experiment.
  The selected solution along with the associated beam parameters is presented.
  
\end{abstract}

\maketitle


\section{INTRODUCTION} \label{sec:introduction}

Particle accelerators play a significant role in many aspects of science and
  technology.
Fields such as material science, chemistry, the biosciences, particle
  physics, nuclear physics and medicine depend on reliable and effective
  particle accelerators, both as research and practical tools.
Achieving the required performance in the design, commissioning, and operation
  of accelerator facilities is a complex and versatile problem.
Despite the success of on-line models in some facilities~\cite{xiaobiao}, 
and various model dependent and model independent tuning and optimization techniques, 
empirical tuning by operators is a common method used at many research facilities.
When the beam dynamics is nonlinear, as is the case with space charge, 
simple and fast models are applicable only in a very restricted manner. 
This further complicates any mult-objective optimization by complicating the model. 
In order to be able to reliably identify optimal configurations of
  accelerators, we solve large multi-objective design optimization
  problems to automate the investigation for an ideal set of tuning parameters.
  This approach has been used in the past with much 
  success~\cite{bazarov05,yrss:09,chao09,gong12,hofler13,jefferson,gong15,gongthesis15,gull1,gull2,marija}.
The difference here being the implementation and application to a 
problem at the Argonne Wakefield Accelerator Facility (AWA).

A hallmark of the AWA facility is the flexibility to swap physical
components in the beamlines, which enables different, often novel,
accelerator research experiments to take place.  Not only do the
physical machine components change, the beam characteristics also vary
considerably to meet different needs.  The facility operates at both low
and high charge (up to 100 nC), and at high charge strong nonlinearities
require a full 3D space charge approach in simulations.  
Finding optics solutions in this regime, especially when
there are additional constraints such as the small aperture two-beam
accelerating structures, is challenging even without the quick
turnaround of the beamline configurations.  Therefore, it has been an
important research objective to develop a precise, e.g. 3D model
embedded into a multi-objective optimization framework that may be used
as a flexible platform for optimization of changing machine
configurations operated at different charge levels. While other codes,
such as GPT~\cite{gpt} and ELEGANT~\cite{elegant}, also have
integrated genetic optimization algorithms; the OPAL~\cite{opal} framework
differentiates itself by being open source (i.e. free to use), massively
parallel, and fully 3D.

\begin{figure}%[h!]
	\center
\includegraphics[width=0.5\textwidth]{opt-framework_code}
\caption{Multi-objective framework: the pilot (master) solves the
	optimization problem specified in the input file by coordinating optimizer
	algorithms and workers running forward solves.}
\label{fig:framenetwork}
\end{figure}

A modular multi-objective software framework was developed (see
 Fig.~\ref{fig:framenetwork}) where the core functionality of the optimizer is decoupled from
 the ``beam dynamics'' but fully integrated in the OPAL framework. 
To that end, we use a master/slave mechanism where a master process governs a
 set of slave processes given some computational tasks (beam dynamics simulation) to complete.
This separation allows easy interchange of optimization algorithms, forward
  solvers and optimization problems.
A ``pilot'' coordinates all efforts between the optimization algorithm and the
  beam dynamics task. Details of the code implementation, e.g. framework components, 
  optimizer and forward solver implementation, and parallelization, can be found in the 
  Supplemental Material at [URL will be inserted by publisher].
In combination, this forms a robust and general framework for massively parallel
  multi-objective optimization.
Currently the framework offers one concrete optimization algorithm, an
  evolutionary algorithm employing a \textsc{NSGA-II} selector~\cite{dpam:02,pisa}.
Normally, simulation based approaches are plagued by the trade off between
  level of detail and time to solution.
This problem is addressed later in Section~(\ref{awa:subsection:test}) by using forward solvers with different time and resolution complexity.

The framework used here, incorporates the following three contributions:
%
\begin{enumerate}
  \item Implementation of a scalable optimization algorithm capable of
        approximating Pareto fronts in high dimensional spaces,
  \item design and implementation of a modular framework that is simple to use
        and deploy on large scale computational resources, and
  \item demonstration of the usefulness of the proposed framework on a real world
        application in the domain of particle accelerators. This is done
        with the optimization problem set as 
        the high charge photoinjector at the AWA. 
\end{enumerate}

The next section introduces the notation of multi-objective optimization
theory and describes the first implemented optimizer.
In Section~\ref{sec:framework}, the implementation of the framework is discussed.
We introduce the employed forward-solver in Section~\ref{sec:forward-solver}.
A validation and a proof of concept application in the beam dynamics problems 
mentioned above is discussed in Section~\ref{sec:experiments}.


\section{MULTI-OBJECTIVE OPTIMIZATION} \label{sec:optimization}

Optimization problems deal with finding one or more feasible solutions
  corresponding to extreme values of objectives.
If more than one objective is present in the optimization problem this is called
  a multi-objective optimization problem (MOOP).
A MOOP is defined as
%
\begin{align}
  \text{ min} \quad & \quad f_m({\bf x}), ~& m &= 1, \dots, M, \label{eq:moop:obj}\\
  \text{s.t.} \quad & \quad g_j({\bf x}) \geq 0, & j &= 0, \dots, J,
  \label{eq:moop:constr}\\
  \quad & \quad  x_i^L \leq {\bf x}=x_i \leq x_i^U,& i &=0, \dots, n
  \label{eq:moop:dvar} \text{,}
\end{align}
%
where $\bf f$ denotes the objectives (\ref{eq:moop:obj}),
  $\bf g$ the constraints (\ref{eq:moop:constr}),
  and $\bf x$ the design variables (\ref{eq:moop:dvar}).
Often, conflicting objectives are encountered, and this complicates the concept of
  optimality. \textit{Pareto optimality} is often used in such situations.
The set of Pareto optimal points forms the Pareto front or
  surface.
All points on this surface are considered to be Pareto optimal.
Sampling Pareto fronts is far from trivial.
A number of approaches have been proposed,
  e.g.\ evolutionary algorithms~\cite{deb:09},
  simulated annealing~\cite{kigv:83},
  swarm methods~\cite{keeb:95},
  and many more~\cite{domc:96,cati:02,kara:05,hoss:09}.
In the next section, we briefly introduce the theory of evolutionary algorithms
  used in the present work.


\subsection{Evolutionary Algorithms}

Evolutionary algorithms are loosely based on nature's evolutionary
  principles to guide a population of individuals towards an improved solution
  by honoring the ``survival of the fittest'' principle.
This ``simulated'' evolutionary process preserves entropy (or diversity in
  biological terms) by applying genetic operators, such as mutation and
  crossover, to remix the fittest individuals in a population.
Maintaining diversity is a crucial feature for the success of all evolutionary
  algorithms.

In general, a generic evolutionary algorithm consists of the following
  components:
%
\begin{itemize}
  \item \textit{Genes}: traits defining an individual,
  \item \textit{Fitness}: a mapping from genes to a fitness value for each
    individual,
  \item \textit{Selector}: selecting the $k$ fittest individuals of a
    population based on some sort of ordering,
  \item \textit{Variator}: recombination (mutations and crossover) operators
    for offspring generation.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{ga_explained_big}
  \caption{Schematic view of interplay between selector and variator. The
  selector ranks all individuals in the population according to fitness and
  subsequently the variator uses the fittest individuals to produces new
  offspring. Finally, the new children are reintroduced in the population.}
  \label{fig:varsel}
\end{figure}

Applied to multi-objective optimization problems, genes correspond to
  design variables.
The fitness of an individual is loosely related to the value of the objective
  functions for the corresponding genes.
Figure~\ref{fig:varsel} schematically depicts the connection of the
  components introduced above.
The process starts with an initially random population of individuals, each
  individual with a unique set of genes and corresponding fitness,
  representing one location in the search space.
In the next step, the population is processed by the selector
  determining the $k$ fittest individuals according to their fitness values.
While the $k$ fittest individuals are passed to the variator, the
  remaining $n-k$ individuals are eliminated from the population.
The \textsc{Variator} mates and recombines the $k$ fittest individuals to
  generate new offspring.
After evaluating the fitness of all the freshly born individuals a
  \textit{generation} cycle has completed and the process can start anew.

Since there already exist plenty of implementations of evolutionary algorithms,
  it was decided to incorporate the PISA library \cite{pisa} into our
  framework.
One of the advantages of PISA is that it separates variator from selector,
  rendering the library expandable and configurable.
Implementing a variator was enough to use PISA in our framework and
  retain access to all available PISA selectors.
As shown in Fig.~\ref{fig:varsel}, the selector is in charge of ordering a
  set of $d$-dimensional vectors and selecting the $k$ fittest individuals
  currently in the population.
The performance of a selector depends on the number of objectives and the
  surface of the search space.
So far, the NSGA-II selector~\cite{dpam:02} has been used and exhibits satisfactory
  convergence performance.

The task of the variator is to generate offspring and ensure diversity in the
  population.
The variator can start generating offspring once the fitness of every
  individual of the population has been evaluated.
This explicit synchronization point defines an obvious bottleneck for parallel
  implementations of evolutionary algorithms.
In the worst case, some MPI processes are taking a long time to compute the
  fitness of the last individual in the pool of individuals to evaluate.
During this time all other resources are idle and wait for the result of
  this one individual in order to continue to generate and evaluate offspring.
To counteract this effect, the selector is already called when two individuals
  have finished evaluating their fitness, lifting the boundaries between
  generations and evaluating the performance of individuals.
New offspring will be generated and MPI processes can immediately return to
  work on the next fitness evaluation.
Calling the selector more frequently (already after two offspring
  individuals have been evaluated) results in better populations since bad
  solutions are rejected earlier.
On the other hand, calling the selector more often is computationally more
  expensive. Note this capability is also present in Cornell's~\cite{bazarov05} 
  and GPT's~\cite{gpt} optimization system. 

The variator implementation uses the master/slave architecture, presented in
  the next section, to run as many function evaluations as possible in parallel.
Additionally, various crossover and mutation policies are available for tuning
  the algorithm to the optimization problem.



\section{THE FRAMEWORK} \label{sec:framework}

Simulation based multi-objective optimization problems are omnipresent in
  research and industry.
These simulation and optimization problems are in
  general very big and computationally demanding.
This motivated us to design a massively parallel general purpose framework.
The key traits of such a design can be summarized as:
%
\begin{itemize}
  \item support any multi-objective optimization method,
  \item support any function evaluator: simulation code or measurements,
  \item offer a general description/specification of objectives, constraints
        and design variables,
  \item run efficiently in parallel on current large-scale high-end clusters
        and supercomputers.
\end{itemize}
%

\subsection{Related Work}

Several similar frameworks, e.g.~\cite{dnld:06, lbjt:07, fide:09,lems:09}, have
  been proposed.
Commonly these frameworks are tightly coupled to an optimization algorithm,
  e.g.\ only providing evolutionary algorithms as optimizers.
Users can specify optimization problems, but cannot change the
  optimization algorithm.
Our framework follows a more general approach, providing a user-friendly way
  to introduce new or choose from existing built-in multi-objective
  optimization algorithms.
Tailoring the optimization algorithm to the optimization problem at hand is
  an important feature due to the many different characteristics of
  optimization problems that should be handled by such a general framework.
As an example, it is shown how \textsc{Pisa}~\cite{pisa}, an existing evolutionary
  algorithm library, was integrated with ease.
Similarly, other multi-objective algorithms could be incorporated and
  used to solve optimization problems.

The framework presented in \cite{lems:09} resembles our implementation the
  most, aside from their tight coupling with an evolutionary algorithm
  optimization strategy.
The authors propose a plug-in based framework employing an island
  parallelization model, where multiple populations are evaluated concurrently
  and independently up to a point where some number of individuals of the
  population are exchanged.
This is especially useful to prevent the search algorithm getting stuck in
  a local minimum.
A set of default plug-ins for genetic operators, selectors and other
  components of the algorithms are provided by their framework.
User-based plug-ins can be incorporated into the framework by implementing a
  simple set of functions.

Additionally, as with simulation based multi-objective optimization, we can
  exploit the fact that both the optimizer and simulation part of the process
  use a certain amount of resources.
The ratio of work between optimizer and simulation costs can be reflected in
  the ratio of number of processors assigned to each task.
This not only provides users with  great flexibility in using any simulation
  or optimizer, but renders influencing the role assignment easy as well.

\input{theor-experiment} 

\section{CONCLUSIONS} \label{sec:conclusions}

A general-purpose framework for solving multi-objective
  optimization problems was presented.
Its modular design simplifies the application to simulation-based optimization
  problems for a wide range of problems and allows to exchange the
  optimization algorithm.
The flexibility of being able to adapt both ends of the optimization
  process, the forward solver and the optimization algorithm simultaneously
  not only leads to broad applicability but it facilitates
  tailoring the optimization strategy to the optimization problem as well.

The framework was integrated into OPAL, and used 
to study a beam dynamics problem at the AWA.
A scan of time step and hyper parameters was done to determine computational settings.
Then a full scale physics optimization was performed.
Optimization of the 3D beam size and energy spread was accomplished.
The TBA beam line presented is currently being installed at the AWA.
Once installation is complete, the results shown here will guide future experiments at the AWA.

In contrast to approaches that are tightly coupled to the optimization
algorithm, the range of possible applications is much wider.
Even in cases where the mathematical model of the forward solver is not known
exactly, fixed or real time measurements can be used to guide the
search for the Pareto optimal solutions.
Finally, combining a multi-objective optimization framework, such as 
the one presented, with practical experience in the field should expedite 
the decision making process in the design and operation of particle accelerators.

 
\section{ACKNOWLEDGMENT}

The authors thank the AWA team for contributing to the
  formulation of optimization problems. 
  We gratefully acknowledge the computing resources provided on Bebop,
  a HPC cluster operated by the LCRC at ANL.
  Thanks to Scott Doran for providing CAD drawings of the AWA beam lines.
  This work was partly supported by the 
  U.S. Department of Energy, Office of Science, under 
  contract number DE-AC02-06CH11357 and grant number DE-SC0015479. 

\bibliography{paper}

\end{document}


